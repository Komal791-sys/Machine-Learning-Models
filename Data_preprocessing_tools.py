# -*- coding: utf-8 -*-
"""Copy of data_preprocessing_tools.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5kiUVW5LJs3NmQSI6UkUjSo6e4sqvz-

# Data Preprocessing Tools

## Importing the libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## Importing the dataset"""

dataset=pd.read_csv('/content/Data.csv')
display(dataset)

"""Features and **labels**"""

X=dataset.iloc[:,:-1].values
y=dataset.iloc[:,-1].values

print(X)
print(y)

"""## Taking care of missing data"""

dataset.isnull().values.any()

dataset.isnull().sum()

from sklearn.impute import SimpleImputer
impute=SimpleImputer(missing_values=np.nan,strategy='mean')
impute.fit(X[:,1:3])
X[:,1:3]=impute.transform(X[:,1:3])

print(X)

"""## Encoding categorical data

### Encoding the Independent Variable
"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')
X=ct.fit_transform(X)

print(X)

"""### Encoding the Dependent Variable"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y=le.fit_transform(y)

print(y)

"""## Splitting the dataset into the Training set and Test set"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)

print(X_train)

print(X_test)

print(y_train)

print(y_test)

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler
ss=StandardScaler()
X_train=ss.fit_transform(X_train)
X_test=ss.fit_transform(X_test)

print(X_train)

print(X_test)

